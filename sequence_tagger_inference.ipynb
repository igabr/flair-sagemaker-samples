{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting FLAIR models on Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is some initial imports and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session() # can use LocalSession() to run container locally\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'flair-input'\n",
    "prefix_output = 'flair-ouput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters of your container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following container will be used for hosting:  763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-inference:1.5.0-gpu-py36-cu101-ubuntu16.04\n"
     ]
    }
   ],
   "source": [
    "# Using Sagemaker PyTorch 1.5 serving container\n",
    "# Full list of available deep learning containers is here: https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html\n",
    "\n",
    "container_serving = \"pytorch-inference\" # your container name\n",
    "tag = \"1.5.0-gpu-py36-cu101-ubuntu16.04\" # you can have several version of container available\n",
    "image = '763104351884.dkr.ecr.{}.amazonaws.com/{}:{}'.format(region, container_serving, tag)\n",
    "\n",
    "print(\"Following container will be used for hosting: \",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy remote endpoint\n",
    "\n",
    "To process inference data when we are sending it over internet, we need to have two customer ser/deser methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel, PyTorch, PyTorchPredictor\n",
    "from sagemaker.estimator import Estimator, Model\n",
    "\n",
    "remote_model = PyTorchModel(name = \"flair-tagger-v2\",\n",
    "                            model_data=\"s3://vadimd-empty-bucket/placeholder/emptyfile.tar.gz\", # This will be replaced with location of trained model artifacts. \n",
    "                                                                                                # For now, default pre-trained FLAIR model will be used.\n",
    "                            role=role,\n",
    "                            sagemaker_session = sess,\n",
    "                            entry_point=\"sequence_tagger_serving.py\",\n",
    "                            source_dir=\"serving_sources\",\n",
    "                            framework_version=\"1.5\", py_version=\"3.6\",\n",
    "                            image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "remote_predictor = remote_model.deploy(instance_type='ml.g4dn.xlarge',\n",
    "                                       initial_instance_count=1,\n",
    "                                       update_endpoint = True, # comment or False if endpoint doesns't exist\n",
    "                                       endpoint_name=\"sequence-endpoint-v1\", # define a unqie endpoint name; if ommited, Sagemaker will generate it based on used container\n",
    "#                                        wait=False\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence: \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"   [− Tokens: 22  − Token-Labels: \"New <B-LOC> York <I-LOC> City <E-LOC> (NYC), often called The <B-LOC> City <E-LOC> or simply New <B-LOC> York <E-LOC> (NY), is the most populous city in the United <B-LOC> States. <E-LOC>\"]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import flair\n",
    "import json\n",
    "\n",
    "# sentence_to_predict = \"Berlin is the capital and largest city of Germany by both area and population.\"\n",
    "sentence_to_predict  = \"New York City (NYC), often called The City or simply New York (NY), is the most populous city in the United States.\"\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "content_type = 'application/json'\n",
    "accept_type = \"pickle\"\n",
    "headers = {'content-type': content_type}\n",
    "payload = json.dumps(sentence_to_predict)\n",
    "endpoint_name = \"sequence-endpoint-v1\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type,\n",
    "    Accept = accept_type\n",
    ")\n",
    "\n",
    "prediction_obj = pickle.loads(response['Body'].read())\n",
    "print(prediction_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
