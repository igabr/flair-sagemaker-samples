{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hosting FLAIR models on Sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    ! pygmentize -l docker Dockerfile.serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in case of training image, we'll need to build and push container to AWS ECR. Before this, we'll need to loging to shared Sagemaker ECR and your local ECR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loging to Sagemaker ECR with Deep Learning Containers\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 763104351884.dkr.ecr.us-east-2.amazonaws.com\n",
    "# loging to your private ECR\n",
    "!aws ecr get-login-password --region us-east-2 | docker login --username AWS --password-stdin 553020858742.dkr.ecr.us-east-2.amazonaws.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build and push container using follow command. Note, that here we supply non-default Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./build_and_push.sh d2-sm-g4-serving latest Dockerfile.serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploying Inference Endpoint\n",
    "\n",
    "Below is some initial imports and configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "import requests\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sess = sagemaker.Session() # can use LocalSession() to run container locally\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "region = \"us-east-2\"\n",
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "prefix_input = 'detectron2-input'\n",
    "prefix_output = 'detectron2-ouput'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters of your container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following container will be used for hosting:  763104351884.dkr.ecr.us-east-2.amazonaws.com/pytorch-inference:1.5.0-gpu-py36-cu101-ubuntu16.04\n"
     ]
    }
   ],
   "source": [
    "# Using Sagemaker PyTorch 1.5 serving container\n",
    "# Full list of available deep learning containers is here: https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html\n",
    "\n",
    "container_serving = \"pytorch-inference\" # your container name\n",
    "tag = \"1.5.0-gpu-py36-cu101-ubuntu16.04\" # you can have several version of container available\n",
    "image = '763104351884.dkr.ecr.{}.amazonaws.com/{}:{}'.format(region, container_serving, tag)\n",
    "\n",
    "print(\"Following container will be used for hosting: \",image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy remote endpoint\n",
    "\n",
    "To process inference data when we are sending it over internet, we need to have two customer ser/deser methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorchModel, PyTorch, PyTorchPredictor\n",
    "from sagemaker.estimator import Estimator, Model\n",
    "\n",
    "remote_model = PyTorchModel(name = \"flair-tagger-v2\",\n",
    "                            model_data=\"s3://vadimd-empty-bucket/placeholder/emptyfile.tar.gz\", # This will be replaced with location of trained model artifacts. \n",
    "                                                                                                # For now, default pre-trained FLAIR model will be used.\n",
    "                            role=role,\n",
    "                            sagemaker_session = sess,\n",
    "                            entry_point=\"sequence_tagger_serving.py\",\n",
    "                            source_dir=\"serving_sources\",\n",
    "                            framework_version=\"1.5\", py_version=\"3.6\",\n",
    "                            image=image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "remote_predictor = remote_model.deploy(instance_type='ml.g4dn.xlarge',\n",
    "                                       initial_instance_count=1,\n",
    "                                       update_endpoint = True, # comment or False if endpoint doesns't exist\n",
    "                                       endpoint_name=\"sequence-endpoint-v1\", # define a unqie endpoint name; if ommited, Sagemaker will generate it based on used container\n",
    "#                                        wait=False\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sentence: \"Berlin is the capital and largest city of Germany by both area and population.\"   [− Tokens: 14  − Token-Labels: \"Berlin <S-LOC> is the capital and largest city of Germany <S-LOC> by both area and population.\"]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get_spans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-47caeceee6a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# iterate over entities and print\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprediction_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get_spans'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import flair\n",
    "import json\n",
    "\n",
    "sentence_to_predict = \"Berlin is the capital and largest city of Germany by both area and population.\"\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "content_type = 'application/json'\n",
    "accept_type = \"pickle\"\n",
    "headers = {'content-type': content_type}\n",
    "payload = json.dumps(sentence_to_predict)\n",
    "endpoint_name = \"sequence-endpoint-v1\"\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    Body=payload,\n",
    "    ContentType=content_type,\n",
    "    Accept = accept_type\n",
    ")\n",
    "\n",
    "prediction_obj = pickle.loads(response['Body'].read())\n",
    "print(prediction_obj)\n",
    "\n",
    "# iterate over entities and print\n",
    "for entity in prediction_obj.get_spans('ner'):\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
